
Encrypted File Trie
~~~~~~~~~~~~~~~~~~~

EFT stores a directory tree and its contents as a bunch of indistinguishable
encrypted blocks.

Security goals:
 * Someone with access to the stored blocks should be unable to determine much
   about the stored file contents and structure.
 * Even if someone is monitoring changes to the stored blocks, they should only
   be able to determine the approximate size of each change.

Performance goals:
  The following operations should be fast and space efficient:
    * Extracting a file or directory listing, even if the blocks are stored
      remotely.
    * Inserting / updating a file or directory listing.
    * Determining the sets of added and deleted blocks after any operation.
    * Snapshotting old versions.
    * Merging two EFTs.


This implementation:
  * Blocks are 16k (data) + 64 bytes (nonce & mac).
  * There are four categories of block:
    * Directory tree structure (a hash-mapped trie)
    * Data block lists (a "number trie")
    * Small data blocks (entities < ~12k)
    * Large data blocks (chunks of entities > ~12k)
  * Each block is referenced by its 32-byte SHA256 hash.
  * Each block is encrypted and authenticated with XSalsa20 + Poly1305 (NACL Secret Box)
  * Blocks are always encrypted.


Operations
~~~~~~~~~~

The EFT supports four basic operations:
 - Put: Add an item at some path.
 - Get: Get an item at some path.
 - Delete: Remove an item at a path.
 - List: List the items in a directory at a path.


Directory Tree Blocks
~~~~~~~~~~~~~~~~~~~~~

Each EFT store is has a single root block identified by its block hash. This
block is the root of a hash trie. This trie maps file system paths to entities
(directories, files, symbolic links) in the file system.

Paths are hashed with SHA256 to form the key.

The trie structure is as described below.

The following tree-specific data is stored in each table entry:
    [34,42]: Size of entity


Small Entity Blocks
~~~~~~~~~~~~~~~~~~~

If an entity is under 12k, it can be stored directly in a single data
block. The extra 4k leaves space for storing keys for the directory tree
trie.

Structure:
    [0,   2k]: Entity Metadata Header
    [2k,  4k]: Reserved
    [4k, 16k]: Data

Entity Metadata Header:
    [0,   4]: Type (directory, file, symlink)
    [4,  12]: Size (uint64)
    [12, 20]: Mtime (uint64, nanoseconds since epoch)
    [20, 24]: Mode (0 = default, 1 = u+x)
    [24, 32]: Reserved
    [32, 64]: Hash
    [512,1k]: Last Modified By (user@host) (4 byte length, 508 bytes data)
    [1k, 2k]: Path (4 byte length, 1020 bytes of data)

Note that this means directories are only needed for traversals. They store
a JSON list of file names and nothing else.

Block Lists
~~~~~~~~~~~

For entities over 12k, it is nessisary to store the list of blocks that
constitute the entity. This list is stored as a trie of block numbers
to block hashes. This has the advantage of allowing reasonably efficient
random reads and writes within a file.

The key used to index the trie is a 64-bit unsigned integer in little-
endian byte order with trailing zero bytes removed. This means that the
depth of the trie will be the minimum that uniquely addresses all the
blocks of the entity.

The byte-trie structure described below is used.

In the root of the trie, the header is the Entity Metadata header.

The following tree-specific data is used in table entries.
    [34, 42]: Data block # (stored as a little-endian uint64)


Large Entity Blocks:
~~~~~~~~~~~~~~~~~~~

These have data in them.



EFT On-Disk Byte Trie:
~~~~~~~~~~~~~~~~~~~~~

On-disk byte tries are used to store both Path -> Item mappings and, within
an Item, Block # -> Block mappings.

Both cases are instances of the generic problem of mapping a sequence of bytes
derived from a key to a block hash.

Each trie node has 256 entries, indexed by one byte in the hash. Entries are
48 bytes, making the total table 12k in size.

Each node in the Trie is structured as follows:

Block list node format:
    [0,   2k]: Header (Tree-specific data)
    [2k,3.5k]: Reserved
    [3.5k,4k]: List of overflow tables
    [4k, 16k]: Table

Table entry structure:
    [0,  32]: Block hash for target or subtrie.
    [32, 33]: Entry type:
        0 = Entry
        1 = Sub-Trie
        2 = An Item
    [34, 42]: (Partial) key
    [42, 48]: Tree-specific data


TODO: Implement overflow tables

In order to save disk space, each table has 16 overflow tables. These are used
to store entries without creating subtries.

When a collision occurs, the first four bits of the next key byte are used to
select an overflow table from the list. This overflow table is like a regular
trie node, except the items in it are kept in no specific order.

Once an overflow table is full, its entries are re-inserted into subtries as
usual.


Garbage Collection
~~~~~~~~~~~~~~~~~~

Figuring out which blocks are no longer used after a sequence of operations
on the EFT is non-trivial, especially when a single block may be referenced
multiple snapshots.

Therefore, a garbage collector is used to find dead blocks.

The garbage collector works as follows:

 1. A list of all blocks is generated by scanning the file system.
 2. This list is then sorted.
 3. Blocks in the list are marked by traversing the EFT from each root
    and marking the active blocks in the list. Blocks can be found in
    the sorted list for marking by binary search.
 4. The list is then scanned for unmarked blocks, which are dead.

TODO: Implement garbage collection


Update Log
~~~~~~~~~~

A log is maintained of all changes to the EFT. This allows EFTs to be merged
by replaying the logs.

Logs should only be maintained for a set amount of time. This limits the
space used by the log and means that evidence of deleted file names is only
preserved for a limited time. This isn't actually implemented yet.

The log is a text file with one event per line. The format is:

Time\tOperation\tPath-or-Hash

The possible events are

T  PUT  /some/path
T  DEL  /some/path
T  CPT  ROOT_HASH

CPT indiates that this is an upload or download checkpoint. These points
are where the EFT was synced with a remote server.




TODO: Implement update log.


Merging EFTs
~~~~~~~~~~~~

EFTs are intended to be used to enable synchronization of directory trees
stored on multiple machines. This means that the tree may be updated in
multiple places "simultaneously" and two copies of the EFT may recieve
conflicting changes.

This can be resolved by merging a remote EFT into the local EFT when a remote
update occurs. The strategy to merge is as follows:

If the root of the remote EFT is the same as for the local EFT, the tries are
identical and the merge is done.

If the remote root is different, then some merge must be performed. The remote
and local EFTs are treated as read-only snapshots and a new merged EFT is
created.

In order to determine how to merge, the logs are compared. There are two easy
cases:

 - If there is a shared prefix followed by only local changes, we take the
   local EFT as the merge result.
 - If there is a shared prefix followed by only remote changes, we take the
   remote EFT as the merge result.
 
And there are two more complicated cases:

 - If there is no shared prefix in the logs, we need to do a full tree merge
   and then replay the logs.
 - If there is a shared prefix followed by changes to both EFTs we replay 
   the logs after the shared prefix.

In either of these cases, we use the local EFT as the initial merged EFT.

To perform a full tree merge, we traverse the remote directory structure and
compare each item to the merged EFT. If the entry is new or newer, we insert
it. Deletes that occured before the beginning of the log on only one side
will be lost.

To replay the logs, we look at each update from either log in chronological
order. If they occur after the entry in the merged EFT, we apply them.


